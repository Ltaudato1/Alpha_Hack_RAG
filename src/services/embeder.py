import numpy as np
from typing import List, Dict, Any, Optional
from services.vector_store import VectorStore


class Embeder:
    """
    ÐšÐ»Ð°ÑÑ ÑÐ¼Ð±ÐµÐ´Ð´ÐµÑ€ Ð´Ð»Ñ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð²Ñ…Ð¾Ð´ÑÑ‰Ð¸Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð².
    """

    def __init__(self, model: Any, store: VectorStore):
        """
        Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÐ¼Ð±ÐµÐ´Ð´ÐµÑ€Ð°.
        Args:
            model (Any): ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð²
            store: Ð­ÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ ÐºÐ»Ð°ÑÑÐ° VectorStore
        """

        self.model = model

        test_embedding = self._safe_embed("test")
        self.embedding_dim = len(test_embedding)

        self.store = store

        print(f"âœ… Ð­Ð¼Ð±ÐµÐ´Ð´ÐµÑ€ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½. Ð Ð°Ð·Ð¼ÐµÑ€Ð½Ð¾ÑÑ‚ÑŒ: {self.embedding_dim}")

    def _safe_embed(self, text: str) -> np.ndarray:
        """Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾Ðµ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð°"""
        embedding = self.model.embed(text)

        if isinstance(embedding, list) and len(embedding) > 0:
            if isinstance(embedding[0], (list, np.ndarray)):
                embedding_array = np.array(embedding[0], dtype=np.float32)
            else:
                embedding_array = np.array(embedding, dtype=np.float32)
        else:
            embedding_array = np.array(embedding, dtype=np.float32)

        norm = np.linalg.norm(embedding_array)
        if norm > 0:
            embedding_array = embedding_array / norm

        return embedding_array

    def generate_embedding(self, text: str) -> np.ndarray:
        """
        Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð° Ð´Ð»Ñ Ñ‚ÐµÐºÑÑ‚Ð°.
        Args:
            text (str): Ð’Ñ…Ð¾Ð´Ð½Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚
        Returns:
            np.ndarray: Ð’ÐµÐºÑ‚Ð¾Ñ€ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð°
        """
        if not text or not text.strip():
            raise ValueError("Ð¢ÐµÐºÑÑ‚ Ð½Ðµ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¿ÑƒÑÑ‚Ñ‹Ð¼")
        return self._safe_embed(text)

    def embed_and_store(self, content: str, metadata: Optional[Dict] = None) -> int:
        """
        ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÑ‚ Ñ‚ÐµÐºÑÑ‚ Ð² ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³ Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð² Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ….
        Args:
            content (str): Ð¢ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ
            metadata (Dict): ÐœÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°
        Returns:
            int: ID ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½Ð¾Ð¹ Ð·Ð°Ð¿Ð¸ÑÐ¸
        """
        embedding = self.generate_embedding(content)

        try:
            self.store.store_embedding(content, embedding, metadata)

        except Exception as e:
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð°: {e}")
            raise

    def batch_embed_and_store(self, documents: List[str], metadata_list: Optional[List[Dict]] = None) -> List[int]:
        """
        ÐŸÐ°ÐºÐµÑ‚Ð½Ð¾Ðµ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ‚ÐµÐºÑÑ‚Ð¾Ð² Ð² ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¸ Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð² Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ….
        Args:
            documents (List[str]): Ð¡Ð¿Ð¸ÑÐ¾Ðº Ñ‚ÐµÐºÑÑ‚Ð¾Ð² Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
            metadata_list (List[Dict]): Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ…
        Returns:
            List[int]: Ð¡Ð¿Ð¸ÑÐ¾Ðº ID ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½Ñ‹Ñ… Ð·Ð°Ð¿Ð¸ÑÐµÐ¹
        """
        if metadata_list is None:
            metadata_list = [{}] * len(documents)

        if len(documents) != len(metadata_list):
            raise ValueError("ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð¸ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð¾Ð»Ð¶Ð½Ð¾ ÑÐ¾Ð²Ð¿Ð°Ð´Ð°Ñ‚ÑŒ")

        print(f"ðŸ”„ Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð² Ð´Ð»Ñ {len(documents)} Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²...")
        res = []
        for doc, metadata in zip(documents, metadata_list):
            res.append(self.embed_and_store(doc, metadata))
        
        return res

    def get_model_info(self) -> Dict[str, Any]:
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð¼Ð¾Ð´ÐµÐ»Ð¸"""
        return {
            'embedding_dim': self.embedding_dim,
            'stored_embeddings_count': self.get_stored_count()
        }
    